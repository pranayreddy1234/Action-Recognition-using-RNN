# Action-Recognition-using-RNN
Research in human action recognition has accelerated significantly since the introduction of
powerful machine learning tools such as Convolutional Neural Networks (CNNs). However,
effective and efficient methods for incorporation of temporal information into CNNs are still being
actively explored in the recent literature. Recurrent neural network (RNN) and long short-term
memory (LSTM) have achieved great success in processing sequential multimedia data and
yielded the state-of-the-art results in speech recognition, digital signal processing, video
processing, and text data analysis. In this project, we propose a novel action recognition method by
processing the video data using convolutional neural network (CNN) and LSTM network.

Data Set
â€¢ We have used UCF-101 dataset which contains 101 actions and
13,320 videos in total. With 13320 videos from 101 action
categories, UCF101 gives one of the largest diversity in terms of
actions and with the presence of large variations in camera
motion, object appearance and pose, object scale, viewpoint,
cluttered background, illumination conditions, etc. As most of the
available action recognition data sets are not realistic and are
staged by actors, UCF101 aims to encourage further research
into action recognition by learning and exploring new realistic
action categories. The action categories can be divided into five
types: 1)Human-Object Interaction 2) Body-Motion Only 3)
Human-Human Interaction 4) Playing Musical Instruments 5)
Sports.

Every infromation related to the project can be found in the above pdf
